# Procesador de Archivos CSV Grandes

Una aplicaciÃ³n TypeScript diseÃ±ada para manejar archivos CSV grandes que no pueden ser cargados en memoria. Este proyecto genera y procesa datos de ventas utilizando tÃ©cnicas de streaming para un rendimiento Ã³ptimo.

## ğŸ“‹ CaracterÃ­sticas

- **GeneraciÃ³n de Datos**: Crea archivos CSV con 1,000,000+ registros usando streaming por lotes
- **Procesamiento de Reportes**: Procesa archivos CSV grandes usando streams de Node.js para evitar problemas de memoria
- **AnÃ¡lisis EstadÃ­stico**: Calcula estadÃ­sticas completas incluyendo desviaciÃ³n estÃ¡ndar
- **Eficiente en Memoria**: Maneja archivos de cualquier tamaÃ±o sin cargarlos completamente en memoria
- **Seguimiento de Progreso**: Indicadores de progreso en tiempo real durante el procesamiento
- **Testing Completo**: Suite de pruebas completa con validaciÃ³n y pruebas de rendimiento

## ğŸ—ï¸ Estructura del Proyecto

```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ generator.ts      # Generador de datos de ventas
â”‚   â”œâ”€â”€ main.ts          # Procesador de reportes
â”‚   â””â”€â”€ index.ts         # Punto de entrada principal
â”œâ”€â”€ test/
â”‚   â””â”€â”€ test.ts          # Suite de pruebas
â”œâ”€â”€ package.json         # Dependencias y scripts
â”œâ”€â”€ tsconfig.json        # ConfiguraciÃ³n de TypeScript
â””â”€â”€ README.md           # Este archivo
```

## ğŸ“Š Esquema de Datos

### Datos de Ventas (`sales.csv`)
| Campo | Tipo | DescripciÃ³n |
|-------|------|-------------|
| id | int | ID secuencial (1 a 1,000,000) |
| order_id | int | Identificador de orden aleatorio |
| customer_id | int | Identificador de cliente aleatorio (1-50,000) |
| total | float | Monto aleatorio ($500.00 - $1800.00) |
| date | datetime | Fecha aleatoria (2020-2025) |

### Reporte de Ventas (`sales_report.csv`)
| Campo | Tipo | DescripciÃ³n |
|-------|------|-------------|
| year | int | AÃ±o |
| month | int | Mes (1-12) |
| month_name | string | Nombre del mes |
| number_of_orders | int | Cantidad de Ã³rdenes |
| max_amount | float | Monto mÃ¡ximo de venta |
| min_amount | float | Monto mÃ­nimo de venta |
| sales_average | float | Promedio de ventas |
| standard_deviation | float | DesviaciÃ³n estÃ¡ndar de ventas |

## ğŸš€ InstalaciÃ³n

1. **Clonar o crear el directorio del proyecto**
2. **Instalar dependencias**:
   ```bash
   npm install
   ```

## ğŸ“– Uso

### Generar Datos de Ventas
Crea `sales.csv` con 1,000,000 registros:
```bash
npm run generate-data
```

### Procesar Reporte de Ventas
Procesa `sales.csv` y crea `sales_report.csv`:
```bash
npm run process-report
```

### Ejecutar Pruebas
Ejecuta la suite completa de pruebas:
```bash
npm test
```

### Compilar Proyecto
Compilar TypeScript a JavaScript:
```bash
npm run build
```

### EjecuciÃ³n Manual
TambiÃ©n puedes ejecutar los programas directamente con ts-node:
```bash
# Generar datos
npx ts-node src/generator.ts

# Procesar reporte
npx ts-node src/main.ts

# Ejecutar pruebas
npx ts-node test/test.ts
```

## ğŸ”§ ConfiguraciÃ³n

### GeneraciÃ³n de Datos Personalizada
```typescript
import { SalesDataGenerator } from './src/generator';

// Crear generador con parÃ¡metros personalizados
const generator = new SalesDataGenerator(
  'ventas_personalizadas.csv',  // Archivo de salida
  2000000,                     // NÃºmero de registros
  20000                        // TamaÃ±o del lote
);

await generator.generate();
```

### Procesamiento de Reportes Personalizado
```typescript
import { SalesProcessor } from './src/main';

// Crear procesador con rutas personalizadas
const processor = new SalesProcessor(
  'ventas_entrada.csv',    // Archivo de entrada
  'reporte_salida.csv'     // Archivo de salida
);

await processor.process();
```

## ğŸ§ª Pruebas

La suite de pruebas incluye:
- **Pruebas de GeneraciÃ³n de Datos**: Valida estructura de registros, rangos y restricciones
- **Pruebas de Procesamiento de Reportes**: Asegura cÃ¡lculos estadÃ­sticos precisos
- **Pruebas de ValidaciÃ³n de Datos**: Verifica integridad y unicidad de datos
- **Pruebas de Rendimiento**: Mide velocidad de procesamiento y eficiencia

Ejecutar con: `npm test`

## ğŸš€ Rendimiento

### Benchmarks (Rendimiento TÃ­pico)
- **GeneraciÃ³n de Datos**: ~50,000-100,000 registros/segundo
- **Procesamiento de Reportes**: ~80,000-120,000 registros/segundo
- **Uso de Memoria**: Constante ~50-100MB independientemente del tamaÃ±o del archivo
- **TamaÃ±o de Archivo**: ~80MB para 1M de registros

### Eficiencia de Memoria
- Utiliza streaming para lectura y escritura
- Procesa datos en lotes configurables
- Uso de memoria constante independientemente del tamaÃ±o del archivo
- Adecuado para archivos con millones o billones de registros

## ğŸ› ï¸ ImplementaciÃ³n TÃ©cnica

### Estrategia de Streaming
- **Streams de Escritura**: Para generar archivos CSV grandes sin acumulaciÃ³n de memoria
- **Streams de Lectura**: Para procesar archivos CSV grandes lÃ­nea por lÃ­nea
- **Transform Streams**: Para procesamiento y validaciÃ³n de datos
- **Procesamiento por Lotes**: TamaÃ±os de lote configurables para rendimiento Ã³ptimo

### Manejo de Errores
- Manejo completo de errores con mensajes detallados
- Seguimiento de progreso con recuperaciÃ³n de interrupciones
- GestiÃ³n de errores del sistema de archivos
- ValidaciÃ³n de datos con reportes de errores informativos

## ğŸ“ Ejemplo de Salida

### Progreso de GeneraciÃ³n
```
ğŸš€ Iniciando generaciÃ³n de 1,000,000 registros...
ğŸ“ Archivo de salida: sales.csv
ğŸ“¦ TamaÃ±o del lote: 10,000
ğŸ“Š Progreso: 10.0% (100,000/1,000,000) - 85,234 registros/seg
ğŸ“Š Progreso: 20.0% (200,000/1,000,000) - 87,532 registros/seg
...
âœ… Â¡GeneraciÃ³n completada exitosamente!
â±ï¸  Tiempo total: 11.73 segundos
ğŸš€ Velocidad promedio: 85,248 registros/segundo
ğŸ“¦ TamaÃ±o del archivo: 79.2 MB
```

### Progreso de Procesamiento
```
ğŸ”„ Procesando datos de ventas desde: sales.csv
ğŸ“Š Generando reporte a: sales_report.csv
ğŸ“ˆ Procesados 100,000 registros - 92,847 registros/seg
ğŸ“ˆ Procesados 200,000 registros - 94,339 registros/seg
...
âœ… Â¡GeneraciÃ³n de reporte completada exitosamente!
â±ï¸  Tiempo total de procesamiento: 10.84 segundos
ğŸš€ Velocidad promedio de procesamiento: 92,251 registros/segundo
ğŸ“ˆ Generados 72 resÃºmenes mensuales
ğŸ“¦ TamaÃ±o del archivo de reporte: 3.2 KB
```

### Ejemplo de Salida del Reporte
```
year,month,month_name,number_of_orders,max_amount,min_amount,sales_average,standard_deviation
2020,1,January,13842,1799.99,500.01,1149.87,375.42
2020,2,February,12634,1799.85,500.15,1151.23,374.89
2020,3,March,13901,1799.92,500.07,1148.94,376.12
...
```

## ğŸ¤ Contribuciones

1. Hacer fork del repositorio
2. Crear una rama de caracterÃ­stica
3. Realizar tus cambios
4. Ejecutar la suite de pruebas
5. Enviar un pull request

## ğŸ“„ Licencia

Licencia MIT - siÃ©ntete libre de usar este proyecto para cualquier propÃ³sito.

## ğŸ› SoluciÃ³n de Problemas

### Problemas Comunes

**Errores de Memoria**: 
- AsegÃºrate de no intentar cargar todo el archivo de una vez
- Reduce el tamaÃ±o del lote si experimentas presiÃ³n de memoria

**Archivo No Encontrado**:
- AsegÃºrate de que `sales.csv` existe antes de ejecutar el procesador de reportes
- Verifica que las rutas de archivos sean correctas para tu sistema operativo

**Problemas de Rendimiento**:
- Ajusta el tamaÃ±o del lote basado en la memoria disponible
- AsegÃºrate de tener suficiente espacio en disco para operaciones temporales

### Soporte
Para problemas o preguntas, por favor revisa la suite de pruebas para ejemplos de patrones de uso apropiados.

## ğŸŒŸ Comandos RÃ¡pidos

```bash
# Instalar dependencias
npm install

# Generar datos de ventas (1M registros)
npm run generate-data

# Procesar reporte de ventas
npm run process-report

# Ejecutar todas las pruebas
npm test

# Compilar a JavaScript
npm run build

# Pipeline completo
npm run generate-data && npm run process-report
```

## ğŸ“ˆ Casos de Uso

Este sistema es ideal para:
- **AnÃ¡lisis de Big Data**: Procesar conjuntos de datos que no caben en memoria
- **Reportes Financieros**: Generar resÃºmenes estadÃ­sticos de datos de ventas
- **Testing de Rendimiento**: Crear conjuntos de datos grandes para pruebas
- **MigraciÃ³n de Datos**: Procesar archivos CSV grandes de forma eficiente
- **AnÃ¡lisis Temporal**: Generar reportes agrupados por perÃ­odos de tiempo

Â¡El proyecto estÃ¡ listo para usar y puede escalar para manejar conjuntos de datos mucho mÃ¡s grandes si es necesario!



